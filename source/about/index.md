---
title: about
date: 2019-07-19 16:41:10
type: "about"
layout: "about"
---

<img style="position:relative;right:100px;float:right" src="/medias/pic/2.jpg" width="15%" height="48%">


# 教育经历
* <b>本科 计算机科学与技术</b>
浙江工业大学
2008/09 - 2012/06

# 公司经历
### 2019.4 - 今
* <b>腾讯 腾讯云网络产品组 高级开发工程师</b>
1. 负责腾讯云私有云网络控制器层面的后台开发。私有网络（Virtual Private Cloud，VPC）是基于腾讯云构建的专属云上网络空间，为腾讯云上的资源提供网络服务，不同私有网络间完全逻辑隔离。可以自定义网络环境、路由表、安全策略等；同时，私有网络支持多种方式连接 Internet、连接其他 VPC、连接本地数据中心，助力轻松部署云上网络。私有云网络是整个腾讯云网络的核心，控制器负责下发数十万台物理机和网关流表。目前腾讯云在全球 25 个地理区域内运营着 53 个可用区，且在计算和网络领域已经迈入“双百时代”（全网服务器总数量突破100万台，带宽峰值突破100T），如何高效、弹性、成本低的实现网络资源的互联互通，是一个充满挑战的课题。控制器层面采用 Mysql 存储流表，zookeeper 作为中间件主动通知物理机和网关收发数据，采用自定义协议或者 protobuf 协议和 dpdk 或者 kernel 数据面做数据互通。
2. 负责基础网络安全组控制层面的后台开发。安全组即虚拟防火墙，具备有状态的数据包过滤功能，用于设置云服务器、负载均衡、云数据库等实例的网络访问控制，控制实例级别的出入流量，是重要的网络安全隔离手段。同私有云网络控制器一样，也是采用 zookeeper 作为中间件通知安全策略，物理机用内核 netfilter framework封包过滤。

### 2018.8 - 2019.4
* <b>SHAREit 研发部 后端高级开发工程师</b>
1. 负责Youtube视频大规模爬取，由原来的单机模式改为分布式爬取。利用 AWS EC2 AutoScaling 集群实现消费者竞争爬取数据和解析， 利用 Mysql 储存关键词爬取进度及数目，利用 Redis 位图实现布隆过滤器进行排重，利用 AWS SQS 实现消息队列缓冲，利用 Dynamodb 实现底层存储，利用 AWS Lambda 实现和ElasticSearch索引同步并提供给服务端查询。由最初的每天不到一万的数据量提升至每天二十万，数据总量达到三千万。DAU日活印度地区两千万，非印地区一千万。
2. 负责Youtube服务端视频源CDN地址解析和客户端众包解析入库，每秒从客户端接收数据量达到2万。利用AWS Aurora数据库存储由服务端解析的链接和客户端上传的链接。支持按国家及城市维度存储。 利用 Redis 分布式锁协调消费者竞争资源，防止重复解析。及时清除过期链接，及时检测302跳转链接和合法性，将链接下发的比率由原来的不到30%提高到四个九，将链接播放秒半成功率提高到80%。后续继续优化方案，将实例数目由原来的100台减少至一半。此项目被公司评为年度优秀项目。

### 2015.10 - 2018.8
* <b>小米 小米电视 服务端高级开发工程师</b>
1. 手机画报是小米手机内置应用，有入口让用户可以选择打开或者关闭。参与设计了后台架构和运营平台，对接了小米推荐系统和数据工厂。主备MySQL作为底层数据库供Django运营平台使用，运营发布数据至Redis，Nginx做负载均衡和反响代理，将请求分发后台Tornado进程，Tornado负责将Redis数据响应给客户端，QPS达到5k。
2. 手机视频实现追剧功能。一旦用户订阅的电视剧有更新，自动对接小米推送系统通知用户。客户端在推送系统上以剧集id注册Topic，服务端定时检测是否有新剧集，有则POST请求推送系统，发PUSH到客户端通知。
3. 小米电视目前在国内销售1000万台，QPS达到两万，但是因为是聚合各方CP资源，在播放视频和浏览数据的时候，经常发生崩溃情况。为了及时了解并记录客户端错误日志，独立设计了报障平台。采用多生产者，多消费者模型开发，并引入Twitter的Kestrel消息队列，接入小米融合云FDS，并加入了OpenFalcon运维监控，实时监控队列情况和请求状况。多个Tornado进程异步接受客户端传来的压缩后的log数据，并及时返回客户端报障ID，log数据最大100k，被发送到Kestrel消息队列后，多个消费者进程从队列读取数据，写入FDS，并将FDS返回后的日志下载链接连同一条报障日志的其他元数据，一起写入运营系统，供客服和开发排查问题，提高播放资源的稳定性。由于Kestrel Python客户端在取数据的时候，并发量高时，容易发生取到同样数据的情况，所以引入分布式锁，解决这类问题。
4. PatchWall是小米电视核心业务，是用户感受最多的地方，也是主营业务。为了拓展国际化业务，小米电视和Google合作开发ATV(Android TV)，开拓进印度、印尼、俄罗斯市场，接入了当地十多家CP。参考国内小米电视后台架构，开发并部署了国际化业务。Service API 利用Python Tornado框架， 搜索引擎采用Solr，缓存层利用Redis 一致性Hash，持久层用到主备模型Mysql和Redis。运营系统基于Django Admin，支持多国语言。结合当地法律等特殊情况，开启多进程，针对所有海报处理成统一格式，加上蒙层和边缘模糊效果。国际版代码称为i18n_cms，i18n_service。针对于不同国家，因为我们是做平台，我拟定方案，代码用一套，代码中的配置信息根据不同国家采用不同配置，数据用多套，即每个国家使用各自独立的数据，每个国家部署独立的机房，这样，对于开发，只需要改一次代码即可。数据标准化，也节省对接成本。
5. 独立开发电视后台APK的触发升级和灰度升级功能，针对电视型号、用户级别、电视系统采用不同的升级策略。为了节省带宽成本，采用灰度升级，灰度升级原理，设置灰度时间范围，按照当前时间的百分比，算出时间窗，根据电视的deviceid的hash值算出是否落入时间窗范围内。

### 2014.8 - 2015.10
* <b>知道创宇 研发部 开发工程师</b>
1. 通过爬虫监控黑客攻击中国政府网站信息，及时给公安部门提供报警信息。
2. 负责星图项目后端系统，后端存储网站漏洞信息，因为没有自建CDN，所以采用GridFS存储图片等静态数据。


### 2013.2 - 2014.8
* <b>百度 移动游戏 RD</b>
1. 主营业务是移动游戏和应用分发，后台主要用C++语言，利用百度自主研发的UB框架，给客户端和中间层提供接口，支持各种业务。QPS达到3k。
2. 独立开发棋牌大厅项目，设计用户抢对奖券活动。后台Nginx+Openresty过滤请求流，多台应用server实现应用逻辑，对奖券存储在Redis，利用Redis的事务功能和原子操作实现库存加减。
3. MySQL存储资源数据，MongoDB负责接口数据。


### 2012.10 - 2013.2
* <b>恒生电子 银行事业部 C后端开发工程师</b>
负责银行理财销售系统低柜开发。


# 联系方式
* <b>电子邮箱</b>
zhengxiexie2@gmail.com
* <b>微信</b>
zhengxiexie
* <b>QQ</b>
373618217
* <b>个人博客</b>
http://zhengxiexie.club
